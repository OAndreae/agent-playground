{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e6afda",
   "metadata": {},
   "source": [
    "# Fireside Chat AI\n",
    "\n",
    "Ever struggled to prepare for a fireside chat or podcast with a guest speaker?\n",
    "\n",
    "This agent automates the research and preparation process, providing you with a comprehensive briefing and insightful questions.\n",
    "\n",
    "#### Core Features:\n",
    "- Researches the guest speaker using a web search tool.\n",
    "- Writes an executive summary of the guest speaker's background and expertise for the host.\n",
    "- Plans a series of questions for the speaker.\n",
    "- Includes source references to increase the user's [Confidence in AI Results](https://blog.langchain.com/the-hidden-metric-that-determines-ai-product-success/).\n",
    "\n",
    "#### Future Work:\n",
    "- Integrate with LangChain's [web page loaders](https://docs.langchain.com/oss/python/integrations/document_loaders#webpages) to access the entire web page content.\n",
    "- Enhance the agent's ability to synthesize information from multiple sources with a more refined prompt.\n",
    "- Incorporate inline citations in the executive summary and Q&A plan.\n",
    "- Add support for proprietary data sources using [custom retrievers](https://docs.langchain.com/oss/python/integrations/retrievers)\n",
    "- Develop evaluation metrics to assess the quality of the briefing and questions.\n",
    "\n",
    "\n",
    "#### Setup\n",
    "Create a `.env` file in the root directory with the following variables:\n",
    "\n",
    "> ```sh\n",
    "> OPENAI_API_KEY=your_openai_api_key\n",
    "> GOOGLE_API_KEY=your_google_api_key\n",
    "> GOOGLE_CSE_ID=your_google_cse_id\n",
    "> ```\n",
    "\n",
    "See the [OpenAI documentation](https://platform.openai.com/docs/api-reference/authentication) for obtaining your OpenAI API key and the [Google Custom Search documentation](https://developers.google.com/custom-search/v1/overview) for obtaining your Google API key and CSE ID.\n",
    "\n",
    "Google provides up to 100 free search queries per day. Additional queries require a project configured with billing information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e550a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final\n",
    "\n",
    "# The guest speaker to research\n",
    "GUEST_SPEAKER: Final = \"Bear Grylls\"\n",
    "\n",
    "# Helps identify the correct person\n",
    "GUEST_SPEAKER_BIO: Final = \"Bear Grylls is a British adventurer and television presenter.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import urllib3\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.tools import tool, Tool\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "\n",
    "# Disable SSL warnings and configure SSL handling\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "@tool(name_or_callable=\"google_search\", description=\"Search Google.\")\n",
    "def google_search(query):\n",
    "    \"\"\"\n",
    "    Perform a Google search for the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "    \n",
    "    Returns:\n",
    "        str: The search results or a fallback message if SSL issues occur.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        search_wrapper = GoogleSearchAPIWrapper()\n",
    "        return search_wrapper.run(query)\n",
    "    except (ssl.SSLError, Exception) as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        return f\"Search failed for query: {query}.\"\n",
    "\n",
    "researcher_prompt = f\"\"\"\n",
    "You are an expert podcast researcher. \n",
    "\n",
    "You are tasked with researching a guest speaker for a podcast episode and producing a script.\n",
    "\n",
    "This episode's guest speaker is:\n",
    "{GUEST_SPEAKER}\n",
    "{GUEST_SPEAKER_BIO}\n",
    "\n",
    "Use the Google Search tool to identify key sources of information about the guest speaker.\n",
    "Output a detailed report for the podcast host, including key talking points and suggested questions for the guest speaker.\n",
    "Include citations for all information sources used.\n",
    "Tailor your questions so that they will be relevant and interesting to the audience: {AUDIENCE_DESCRIPTION}.\n",
    "\n",
    "Output format\n",
    "\n",
    "# <speaker name>\n",
    "\n",
    "## Bio\n",
    "<executive summary bio of the guest speaker, based on research. Two paragraphs.>\n",
    "\n",
    "Key talking points you can weave into the interview:\n",
    "- <talking point 1>\n",
    "- <talking point 2>\n",
    "- etc.\n",
    "\n",
    "## Questions\n",
    "- <question 1>\n",
    "- <question 2>\n",
    "- etc.\n",
    "\n",
    "## Sources\n",
    "- <source 1 name (description)>: <markdown link to source 1>\n",
    "- <source 2 name (description)>: <markdown link to source 2>\n",
    "- etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "research_agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[google_search],\n",
    "    prompt=SystemMessage(content=researcher_prompt)\n",
    ")\n",
    "\n",
    "try:\n",
    "    research_agent_response = research_agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=f\"Research {GUEST_SPEAKER}\"),\n",
    "                AIMessage(content=f\"#{GUEST_SPEAKER}\\n\"),\n",
    "            ]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(f\"Successfully researched {GUEST_SPEAKER}\")\n",
    "except Exception as e:\n",
    "    print(f\"Research failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ba3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(Markdown(f\"## Research Briefing for {GUEST_SPEAKER}\"))\n",
    "guest_speaker_briefing = research_agent_response[-1]['agent']['messages'][0].content\n",
    "display(Markdown(guest_speaker_briefing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pu5fuikhod",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Pretty-print the full response as JSON\n",
    "\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def serialize_response(obj):\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        return {k: serialize_response(v) for k, v in obj.__dict__.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [serialize_response(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: serialize_response(v) for k, v in obj.items()}\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "serialized_response = serialize_response(research_agent_response)\n",
    "formatted_json = json.dumps(serialized_response, indent=2, ensure_ascii=False)\n",
    "\n",
    "display(Markdown(f\"```json\\n{formatted_json}\\n```\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
